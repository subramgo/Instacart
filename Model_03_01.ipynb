{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>in_next_order</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>avg_days_since_prior_order</th>\n",
       "      <th>prev_order_dow</th>\n",
       "      <th>prev_order_hour_of_day</th>\n",
       "      <th>...</th>\n",
       "      <th>p_reorders</th>\n",
       "      <th>p_reorder_rate</th>\n",
       "      <th>tot_orders</th>\n",
       "      <th>tot_prods</th>\n",
       "      <th>avg_basket</th>\n",
       "      <th>avg_reorder</th>\n",
       "      <th>std_basket</th>\n",
       "      <th>up_orders</th>\n",
       "      <th>up_reorder</th>\n",
       "      <th>up_reorder_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17122</td>\n",
       "      <td>1187899</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>9849.0</td>\n",
       "      <td>0.676907</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>2.110579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>1187899</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>29012.0</td>\n",
       "      <td>0.777843</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>2.110579</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26405</td>\n",
       "      <td>1187899</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>598.0</td>\n",
       "      <td>0.453374</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>2.110579</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>1187899</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2581.0</td>\n",
       "      <td>0.661117</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>2.110579</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>39657</td>\n",
       "      <td>1187899</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4054.0</td>\n",
       "      <td>0.768094</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>2.110579</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  order_id  in_next_order  order_dow  order_hour_of_day  \\\n",
       "0        1       17122   1187899              0          4                  8   \n",
       "1        1         196   1187899              1          4                  8   \n",
       "2        1       26405   1187899              1          4                  8   \n",
       "3        1       13032   1187899              1          4                  8   \n",
       "4        1       39657   1187899              1          4                  8   \n",
       "\n",
       "   days_since_prior_order  avg_days_since_prior_order  prev_order_dow  \\\n",
       "0                    14.0                   19.200001               4   \n",
       "1                    14.0                   19.200001               4   \n",
       "2                    14.0                   19.200001               4   \n",
       "3                    14.0                   19.200001               4   \n",
       "4                    14.0                   19.200001               4   \n",
       "\n",
       "   prev_order_hour_of_day       ...         p_reorders  p_reorder_rate  \\\n",
       "0                       8       ...             9849.0        0.676907   \n",
       "1                       8       ...            29012.0        0.777843   \n",
       "2                       8       ...              598.0        0.453374   \n",
       "3                       8       ...             2581.0        0.661117   \n",
       "4                       8       ...             4054.0        0.768094   \n",
       "\n",
       "   tot_orders  tot_prods  avg_basket  avg_reorder  std_basket  up_orders  \\\n",
       "0          11         70    6.363636     4.636364    2.110579          1   \n",
       "1          11         70    6.363636     4.636364    2.110579         11   \n",
       "2          11         70    6.363636     4.636364    2.110579          3   \n",
       "3          11         70    6.363636     4.636364    2.110579          4   \n",
       "4          11         70    6.363636     4.636364    2.110579          2   \n",
       "\n",
       "   up_reorder  up_reorder_rate  \n",
       "0           0         0.000000  \n",
       "1          10         0.909091  \n",
       "2           2         0.666667  \n",
       "3           3         0.750000  \n",
       "4           1         0.500000  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "features = pd.read_csv('./features/features_train.csv')\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'user_id', u'product_id', u'order_id', u'in_next_order', u'order_dow',\n",
       "       u'order_hour_of_day', u'days_since_prior_order',\n",
       "       u'avg_days_since_prior_order', u'prev_order_dow',\n",
       "       u'prev_order_hour_of_day', u'prev_days_since_prior_order', u'aisle_id',\n",
       "       u'department_id', u'p_orders', u'p_reorders', u'p_reorder_rate',\n",
       "       u'tot_orders', u'tot_prods', u'avg_basket', u'avg_reorder',\n",
       "       u'std_basket', u'up_orders', u'up_reorder', u'up_reorder_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "* Order features\n",
    "    * Current Order -  u'order_dow', u'order_hour_of_day', u'days_since_prior_order'\n",
    "    * Prev Order - u'prev_order_dow',u'prev_order_hour_of_day', u'prev_days_since_prior_order'\n",
    "\n",
    "* User Order Features\n",
    "    * u'avg_days_since_prior_order\n",
    "\n",
    "* Product Features\n",
    "    * u'aisle_id', u'department_id'\n",
    "    * u'p_orders', u'p_reorders', u'p_reorder_rate'\n",
    "\n",
    "* User Features\n",
    "    * u'tot_orders', u'tot_prods', u'avg_basket', u'avg_reorder', u'std_basket'\n",
    "\n",
    "* User Product Features\n",
    "    * u'up_orders', u'up_reorder', u'up_reorder_rate'\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "## 1. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dummy variables for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>avg_days_since_prior_order</th>\n",
       "      <th>prev_days_since_prior_order</th>\n",
       "      <th>p_orders</th>\n",
       "      <th>p_reorders</th>\n",
       "      <th>p_reorder_rate</th>\n",
       "      <th>tot_orders</th>\n",
       "      <th>tot_prods</th>\n",
       "      <th>avg_basket</th>\n",
       "      <th>avg_reorder</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_order_hour_of_day_14</th>\n",
       "      <th>prev_order_hour_of_day_15</th>\n",
       "      <th>prev_order_hour_of_day_16</th>\n",
       "      <th>prev_order_hour_of_day_17</th>\n",
       "      <th>prev_order_hour_of_day_18</th>\n",
       "      <th>prev_order_hour_of_day_19</th>\n",
       "      <th>prev_order_hour_of_day_20</th>\n",
       "      <th>prev_order_hour_of_day_21</th>\n",
       "      <th>prev_order_hour_of_day_22</th>\n",
       "      <th>prev_order_hour_of_day_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14550.0</td>\n",
       "      <td>9849.0</td>\n",
       "      <td>0.676907</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37298.0</td>\n",
       "      <td>29012.0</td>\n",
       "      <td>0.777843</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>0.453374</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3904.0</td>\n",
       "      <td>2581.0</td>\n",
       "      <td>0.661117</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5278.0</td>\n",
       "      <td>4054.0</td>\n",
       "      <td>0.768094</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   days_since_prior_order  avg_days_since_prior_order  \\\n",
       "0                    14.0                   19.200001   \n",
       "1                    14.0                   19.200001   \n",
       "2                    14.0                   19.200001   \n",
       "3                    14.0                   19.200001   \n",
       "4                    14.0                   19.200001   \n",
       "\n",
       "   prev_days_since_prior_order  p_orders  p_reorders  p_reorder_rate  \\\n",
       "0                         14.0   14550.0      9849.0        0.676907   \n",
       "1                         14.0   37298.0     29012.0        0.777843   \n",
       "2                         14.0    1319.0       598.0        0.453374   \n",
       "3                         14.0    3904.0      2581.0        0.661117   \n",
       "4                         14.0    5278.0      4054.0        0.768094   \n",
       "\n",
       "   tot_orders  tot_prods  avg_basket  avg_reorder            ...              \\\n",
       "0          11         70    6.363636     4.636364            ...               \n",
       "1          11         70    6.363636     4.636364            ...               \n",
       "2          11         70    6.363636     4.636364            ...               \n",
       "3          11         70    6.363636     4.636364            ...               \n",
       "4          11         70    6.363636     4.636364            ...               \n",
       "\n",
       "   prev_order_hour_of_day_14  prev_order_hour_of_day_15  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   prev_order_hour_of_day_16  prev_order_hour_of_day_17  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   prev_order_hour_of_day_18  prev_order_hour_of_day_19  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   prev_order_hour_of_day_20  prev_order_hour_of_day_21  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   prev_order_hour_of_day_22  prev_order_hour_of_day_23  \n",
       "0                        0.0                        0.0  \n",
       "1                        0.0                        0.0  \n",
       "2                        0.0                        0.0  \n",
       "3                        0.0                        0.0  \n",
       "4                        0.0                        0.0  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = features.ix[:,3]\n",
    "X = features.ix[:,4:]\n",
    "\n",
    "X = pd.get_dummies(X, prefix=['aisle_id','department_id','order_dow',\n",
    "                              'order_hour_of_day','prev_order_dow','prev_order_hour_of_day']\n",
    "                   , columns=['aisle_id','department_id','order_dow',\n",
    "                              'order_hour_of_day','prev_order_dow','prev_order_hour_of_day'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convienient scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "def print_acc(Y, y_p, model_name):\n",
    "    print model_name + \" {0:.2f}, precision {0:.2f}, recall {0:.2f}, f1-score {0:.2f}\"\\\n",
    "                    .format(accuracy_score(Y, y_p)\n",
    "                            , precision_score(Y, y_p)\n",
    "                            , recall_score(Y, y_p)\n",
    "                            , f1_score(Y, y_p))\n",
    "    print\n",
    "    print confusion_matrix(Y, y_p, labels =[0,1])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Model , strategy: stratified,accuracy 0.82, precision 0.82, recall 0.82, f1-score 0.82\n",
      "\n",
      "[[6898652  747185]\n",
      " [ 747409   81415]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "dummy = DummyClassifier(strategy='stratified', random_state = 100, constant = None)\n",
    "dummy.fit(X.values, Y.values)\n",
    "y_p1 = dummy.predict(X.values)\n",
    "\n",
    "print_acc(Y.values, y_p1, \"DummyClassifier\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "\n",
    "* 5 Estimators\n",
    "    RandomForestClassifier accuracy 0.98, precision 0.98, recall 0.98, f1-score 0.98\n",
    "    f1-score 0.619361997852\n",
    "* 50 Estimators\n",
    "    RandomForestClassifier 1.00, precision 1.00, recall 1.00, f1-score 1.00\n",
    "    f1-score 0.695119773475\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      " building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  2.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  4.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  5.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 25.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 27.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 31.8min finished\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "print_acc() takes exactly 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f2509e65d450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"RandomForestClassifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: print_acc() takes exactly 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 50, \n",
    "                                oob_score = True, \n",
    "                                random_state = 100,\n",
    "                                verbose = 10, \n",
    "                                n_jobs=-1)\n",
    "forest.fit(X.values, Y.values)\n",
    "\n",
    "print \"Predicting\"\n",
    "y_p2 = forest.predict(X.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 1.00, precision 1.00, recall 1.00, f1-score 1.00\n",
      "\n",
      "[[7645837       0]\n",
      " [   5656  823168]]\n"
     ]
    }
   ],
   "source": [
    "print_acc(Y.values, y_p2,\"RandomForestClassifier\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(forest, open('./models/RF_nestimatros_50.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "\n",
    "## 2. Model Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def f1_score_dict(predicted, actual):\n",
    "    \"\"\" calculate the f1-socre \n",
    "        precision = relevant returned / total returned \n",
    "        recall    = relevant returned / total relevant\n",
    "    \"\"\"\n",
    "    precision_scores = []\n",
    "    recall_scores    = []\n",
    "    f1_scores        = []\n",
    "\n",
    "    if len(predicted) != len(actual):\n",
    "        print \"Error: Lenght of prediction and recall doesnt match\"\n",
    "        return 0\n",
    "\n",
    "    for order_id, products in predicted.items():\n",
    "\n",
    "\n",
    "        preds = products\n",
    "        acts  = actual[order_id]\n",
    "        \n",
    "        if len(preds) == 0:\n",
    "            preds = ['None']\n",
    "\n",
    "        total_returned = len(preds) \n",
    "        total_relevant = len(acts)\n",
    "\n",
    "        relevant_returned = len( set(preds).intersection(set(acts) ) )\n",
    "\n",
    "\n",
    "        prec = relevant_returned / ( 1.0 * total_returned )\n",
    "        rec  = relevant_returned / ( 1.0 * total_relevant )\n",
    "\n",
    "        if rec != 0:\n",
    "            f1   =  2 * ( (prec * rec) / (prec + rec) )\n",
    "        else:\n",
    "            f1   = 0\n",
    "\n",
    "        precision_scores.append(prec)\n",
    "        recall_scores.append(rec)\n",
    "        f1_scores.append( f1)\n",
    "\n",
    "\n",
    "    return sum(f1_scores) / (1.0 * len(f1_scores))\n",
    "\n",
    "def get_f1_score(features, y_p):\n",
    "    \n",
    "    train = pd.read_csv('./data/order_products__train.csv')\n",
    "\n",
    "    train.reordered = train.reordered.astype(np.int8)\n",
    "    train.add_to_cart_order = train.add_to_cart_order.astype(np.int16)\n",
    "\n",
    "    print \"Make a df\"\n",
    "    predicted_df = pd.concat([ features[['user_id','product_id','nxt_order_id'] ] \n",
    "                                        , pd.DataFrame(y_p, columns = ['in_basket'])], axis = 1)\n",
    "\n",
    "\n",
    "    \n",
    "    actual_ = {}\n",
    "    print \"Actual\"\n",
    "    for row in train.itertuples():\n",
    "        order_id = str(row.order_id)\n",
    "        product_id = str(row.product_id)\n",
    "\n",
    "        if order_id not in actual_:\n",
    "            actual_[order_id] = []\n",
    "        actual_[order_id].append(product_id)\n",
    "\n",
    "    predicted_ = {}\n",
    "\n",
    "    print \"Predicted\"\n",
    "    for row in predicted_df.itertuples():\n",
    "        order_id = str(row.nxt_order_id)\n",
    "        product_id = str(row.product_id)\n",
    "\n",
    "\n",
    "        if order_id not in predicted_:\n",
    "            predicted_[order_id] = []\n",
    "        if row.in_basket > 0:\n",
    "            predicted_[order_id].append(product_id)\n",
    "\n",
    "    print \"find f1-score\"\n",
    "\n",
    "    print f1_score_dict(predicted_, actual_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_predictions(feature_file, model, find_f1=False, is_train = True,\n",
    "                        is_prob = True, \n",
    "                        prob_threshold = 0.2, make_submission = False, submission_file = 'submission.csv'):\n",
    "    \n",
    "    print \"Read feature file\"\n",
    "    test_df = pd.read_csv(feature_file)\n",
    "    \n",
    "    starting_index \n",
    "    X_ = test_df.ix[:,4:]\n",
    "\n",
    "    print \"Make dummy variables\"\n",
    "    X_ = pd.get_dummies(X_, prefix=['aisle_id','department_id','order_dow',\n",
    "                              'order_hour_of_day','prev_order_dow','prev_order_hour_of_day']\n",
    "                   , columns=['aisle_id','department_id','order_dow',\n",
    "                              'order_hour_of_day','prev_order_dow','prev_order_hour_of_day'])\n",
    "    \n",
    "    print \"Perform Predictions\"\n",
    "\n",
    "    predictions = None\n",
    "    predictions_prob = None\n",
    "\n",
    "    if not is_prob:\n",
    "        predictions = forest_loaded.predict(X_.values)\n",
    "    else:\n",
    "        predictions_prob = forest_loaded.predict_proba(X_.values)\n",
    "        predictions = []\n",
    "        for rw in predictions_prob:\n",
    "            if rw[1] >= prob_threshold:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "    \n",
    "    if find_f1:\n",
    "        print \"Get f1 score\"\n",
    "        get_f1_score(test_df, predictions)\n",
    "    \n",
    "\n",
    "\n",
    "    if make_submission:\n",
    "\n",
    "        print \"Preparing to make submission\"\n",
    "\n",
    "\n",
    "        final_predictions = pd.concat([ test_df[['user_id','order_id','product_id'] ] \n",
    "                                        , pd.DataFrame(predictions, columns = ['in_basket'])], axis = 1)\n",
    "        \n",
    "        print \"Sort the orders\"\n",
    "        final_predictions.sort(columns = 'order_id', inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "        final = {}\n",
    "\n",
    "        for row in final_predictions.itertuples():\n",
    "            order_id   = row.order_id\n",
    "            product_id = row.product_id \n",
    "            in_basket  = row.in_basket\n",
    "            if order_id not in final:\n",
    "                final[order_id] = []\n",
    "            if in_basket > 0:\n",
    "                final[order_id].append(str(product_id))\n",
    "\n",
    "        print \"Make submission file\"\n",
    "\n",
    "        i = open(submission_file, 'w')  \n",
    "        i.write('order_id,products' + '\\n')\n",
    "        for k,v in final.items():\n",
    "            order_id = str(k)\n",
    "            product_string = ' '.join(v)\n",
    "            if len(product_string) < 1:\n",
    "                product_string = 'None'\n",
    "            to_write = order_id + ',' + product_string + '\\n'\n",
    "            i.write(to_write)\n",
    "\n",
    "        i.close()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print \"Loading model\"\n",
    "import pickle\n",
    "forest_loaded = pickle.load(open('./models/RF_nestimatros_50.pkl','r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "            oob_score=True, random_state=100, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read feature file\n",
      "Make dummy variables\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1219815c2bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0;34m,\u001b[0m\u001b[0mfind_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;34m,\u001b[0m\u001b[0mis_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                    , prob_threshold = 0.2)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-283ebcce1370>\u001b[0m in \u001b[0;36mperform_predictions\u001b[0;34m(feature_file, model, find_f1, is_prob, prob_threshold, make_submission, submission_file)\u001b[0m\n\u001b[1;32m     11\u001b[0m                               'order_hour_of_day','prev_order_dow','prev_order_hour_of_day']\n\u001b[1;32m     12\u001b[0m                    , columns=['aisle_id','department_id','order_dow',\n\u001b[0;32m---> 13\u001b[0;31m                               'order_hour_of_day','prev_order_dow','prev_order_hour_of_day'])\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Perform Predictions\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/reshape.pyc\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[1;32m   1090\u001b[0m                                     drop_first=drop_first)\n\u001b[1;32m   1091\u001b[0m             \u001b[0mwith_dummies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         result = _get_dummies_1d(data, prefix, prefix_sep, dummy_na,\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    833\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m                        copy=copy)\n\u001b[0;32m--> 835\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m   1024\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m                 concat_axis=self.axis, copy=self.copy)\n\u001b[0m\u001b[1;32m   1026\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   4472\u001b[0m                                                 copy=copy),\n\u001b[1;32m   4473\u001b[0m                          placement=placement)\n\u001b[0;32m-> 4474\u001b[0;31m               for placement, join_units in concat_plan]\n\u001b[0m\u001b[1;32m   4475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m   4575\u001b[0m         \u001b[0mconcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4577\u001b[0;31m             \u001b[0mconcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4578\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4579\u001b[0m         \u001b[0mconcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "perform_predictions( feature_file = './features/features_train.csv', model = forest_loaded\n",
    "                    ,find_f1 = True\n",
    "                    ,is_prob = True\n",
    "                   , prob_threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "perform_predictions(  feature_file = './data/features_test.csv', model = forest_loaded\n",
    "                    , find_f1 = True\n",
    "                    , is_prob = True\n",
    "                    , prob_threshold = 0.2\n",
    "                    , make_submission = True, submission_file = 'submission_rf.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
